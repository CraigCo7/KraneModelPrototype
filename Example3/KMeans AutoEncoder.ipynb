{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b89629a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2354, 83)\n",
      "X_test shape: (589, 83)\n",
      "y_train shape: (2354,)\n",
      "y_test shape: (589,)\n"
     ]
    }
   ],
   "source": [
    "from bom import featureEngineer\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bomDf = featureEngineer('Example 3 BOM - Rack 1 and 4.csv')\n",
    "\n",
    "columns_to_exclude = [\n",
    "        'ISO', 'Spool', 'Subsystem', 'Pressure', 'Hydro Group', 'Module', 'EHT', 'Insul', 'Stage']\n",
    "df = bomDf.drop(columns=columns_to_exclude, axis=1)\n",
    "\n",
    "# Specify the features (X) and the target variable (y)\n",
    "X = df.drop(columns=['Output Rack'])  \n",
    "y = df['Output Rack']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Adjust the test_size parameter based on your preference\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"X_train shape:\", x_train.shape)\n",
    "print(\"X_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Determine input shape\n",
    "input_shape = (X.shape[1],)  # Number of features in the DataFrame\n",
    "input_var = keras.Input(shape=input_shape)\n",
    "\n",
    "encoding_dim = X.shape[1]//4\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_var)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(X.shape[1], activation='tanh')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "569a5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_var, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f60d8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_var, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea3e8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our encoded (32-dimensional) input\n",
    "# encoding_dim = X.shape[1]//4\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9063a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using MSE loss function and Adam optimizer\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "146ce79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s 20ms/step - loss: 10196.3301 - val_loss: 23204.9668\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23947.4707 - val_loss: 23181.4551\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23929.5078 - val_loss: 23170.1797\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 7555.7441 - val_loss: 1164.3491\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1006.2512 - val_loss: 1175.2960\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 964.3522 - val_loss: 826.9584\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 838.0882 - val_loss: 864.5717\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 8148.8506 - val_loss: 12786.5879\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 18040.6074 - val_loss: 21377.1133\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 22527.7637 - val_loss: 22003.1797\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 22935.3672 - val_loss: 21776.7852\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 22872.0312 - val_loss: 22381.4668\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23300.7500 - val_loss: 22382.2891\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23394.8301 - val_loss: 22617.2051\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23412.2988 - val_loss: 22594.0801\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23407.9727 - val_loss: 22571.0820\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23673.6562 - val_loss: 23169.4395\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23928.5332 - val_loss: 23153.8613\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23543.6738 - val_loss: 22315.4688\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 21638.1992 - val_loss: 22563.8613\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23439.5566 - val_loss: 21731.0312\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 21737.9395 - val_loss: 16971.0254\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 18985.9492 - val_loss: 20039.5547\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 21151.4824 - val_loss: 22744.3086\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 13683.5400 - val_loss: 23150.2109\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23904.5801 - val_loss: 23130.8496\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23888.1777 - val_loss: 23082.7734\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23752.9785 - val_loss: 22931.0059\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23629.8965 - val_loss: 22872.7461\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23601.2637 - val_loss: 22872.7461\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23596.7539 - val_loss: 22872.7441\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23595.4062 - val_loss: 22872.7461\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23598.5430 - val_loss: 22872.7520\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23595.7402 - val_loss: 22873.1777\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23596.5684 - val_loss: 22873.1816\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23599.6641 - val_loss: 22872.7676\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23600.7812 - val_loss: 22873.1816\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23598.6758 - val_loss: 22873.1777\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23598.6113 - val_loss: 22872.7676\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23599.3496 - val_loss: 22872.7676\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23599.2539 - val_loss: 22872.7676\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23599.1309 - val_loss: 22872.7676\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23598.4805 - val_loss: 22873.1758\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23597.9199 - val_loss: 22873.1777\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23598.6074 - val_loss: 22872.7676\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23599.1328 - val_loss: 22872.7676\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23598.6074 - val_loss: 22872.7676\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 23599.3711 - val_loss: 22872.7676\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23599.4375 - val_loss: 22872.9863\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 23595.5156 - val_loss: 22872.7676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17979db90>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train for 50 epochs\n",
    "\n",
    "# Have to change the type or else it won't be able to convert to tensor.\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f4890a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 1ms/step\n",
      "[[  0.         0.         0.       ...   0.        35.31983  151.04398 ]\n",
      " [  0.         0.         0.       ...   0.        42.552746 185.90814 ]\n",
      " [  0.         0.         0.       ...   0.       100.82235  426.17404 ]\n",
      " ...\n",
      " [  0.         0.         0.       ...   0.       118.6686   497.85278 ]\n",
      " [  0.         0.         0.       ...   0.        56.064278 255.20044 ]\n",
      " [  0.         0.         0.       ...   0.        32.489513 152.2771  ]]\n",
      "(589, 20)\n"
     ]
    }
   ],
   "source": [
    "encoded = encoder.predict(x_test)\n",
    "print(encoded)\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded = decoder.predict(encoded)\n",
    "# print(decoded)\n",
    "# print(decoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69058860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.cluster import KMeans\n",
    "# import pandas as pd\n",
    "\n",
    "# num_clusters = 25\n",
    "\n",
    "# kmeans = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "# sc = MinMaxScaler(feature_range=(0, 1))\n",
    "# X = sc.fit_transform(encoded)\n",
    "\n",
    "# kmeans.fit(X)\n",
    "# # kmeans.fit(data[0])\n",
    "# cluster_assignments = kmeans.labels_\n",
    "# print(cluster_assignments)\n",
    "# print(len(cluster_assignments))\n",
    "\n",
    "# # Create a dictionary to store data points for each cluster\n",
    "# clustered_data = {cluster_num: [] for cluster_num in range(num_clusters)}\n",
    "\n",
    "# # Assign data points to their respective clusters\n",
    "# for i in range(len(X)):\n",
    "#     cluster_num = cluster_assignments[i]\n",
    "#     row = bomDf[bomDf['ID'] == i]\n",
    "#     clustered_data[cluster_num].append(row['Spool'].values)\n",
    "\n",
    "# # print(\"Lengths of arrays:\")\n",
    "\n",
    "# # for key, value in clustered_data.items():\n",
    "# #     print(f\"{key}: {len(value)}\")\n",
    "\n",
    "# max_length = max(len(value) for value in clustered_data.values())\n",
    "\n",
    "# # Fill in with None for arrays with shorter length\n",
    "# clustered_data_filled = {\n",
    "#     key: value + [None] * (max_length - len(value)) for key, value in clustered_data.items()}\n",
    "\n",
    "# # print(\"Lengths of arrays:\")\n",
    "\n",
    "# # for key, value in clustered_data_filled.items():\n",
    "# #     print(f\"{key}: {len(value)}\")\n",
    "\n",
    "# df = pd.DataFrame(clustered_data_filled)\n",
    "\n",
    "# df\n",
    "# # Save the DataFrame to a CSV file\n",
    "# # df.to_csv('Example3SpoolClusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ebf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
