{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89629a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2354, 83)\n",
      "X_test shape: (589, 83)\n",
      "y_train shape: (2354,)\n",
      "y_test shape: (589,)\n"
     ]
    }
   ],
   "source": [
    "from bom import featureEngineer\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bomDf = featureEngineer('Example 3 BOM - Rack 1 and 4.csv')\n",
    "\n",
    "columns_to_exclude = [\n",
    "        'ISO', 'Spool', 'Subsystem', 'Pressure', 'Hydro Group', 'Module', 'EHT', 'Insul', 'Stage']\n",
    "df = bomDf.drop(columns=columns_to_exclude, axis=1)\n",
    "\n",
    "# Specify the features (X) and the target variable (y)\n",
    "X = df.drop(columns=['Output Rack'])  \n",
    "y = df['Output Rack']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Adjust the test_size parameter based on your preference\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"X_train shape:\", x_train.shape)\n",
    "print(\"X_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Determine input shape\n",
    "input_shape = (X.shape[1],)  # Number of features in the DataFrame\n",
    "input_var = keras.Input(shape=input_shape)\n",
    "\n",
    "encoding_dim = X.shape[1]//4\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_var)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(X.shape[1], activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a8fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_var, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f60d8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_var, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da013aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our encoded (32-dimensional) input\n",
    "# encoding_dim = X.shape[1]//4\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e951a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using MSE loss function and Adam optimizer\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf5686b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s 14ms/step - loss: -344076.5625 - val_loss: -336277.0938\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -353023.5625 - val_loss: -345031.7188\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -362133.6562 - val_loss: -353853.7188\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -371338.4688 - val_loss: -362816.5000\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -380780.9688 - val_loss: -371934.4375\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -390341.5312 - val_loss: -381266.0000\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: -400120.1875 - val_loss: -390794.7500\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -409970.5312 - val_loss: -400371.7188\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 6ms/step - loss: -420070.0000 - val_loss: -410118.7812\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -430223.4062 - val_loss: -420117.0625\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -440700.4688 - val_loss: -430279.2188\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -451350.9062 - val_loss: -440673.2188\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -462183.9062 - val_loss: -451146.0000\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -473137.8125 - val_loss: -461895.8750\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -484400.5625 - val_loss: -472727.7812\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -495784.7812 - val_loss: -483749.9688\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -507285.9688 - val_loss: -495092.2500\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -519072.5625 - val_loss: -506478.0625\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -530996.5000 - val_loss: -518075.7188\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -543144.8125 - val_loss: -529923.3750\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -555404.4375 - val_loss: -541800.1875\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -567911.3750 - val_loss: -553847.1875\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -580450.3750 - val_loss: -566242.1250\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -593510.2500 - val_loss: -578746.0625\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -606659.5000 - val_loss: -591658.6875\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -620062.3750 - val_loss: -604708.7500\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -633694.9375 - val_loss: -618042.1875\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -647678.5625 - val_loss: -631634.8125\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -661959.5625 - val_loss: -645328.6875\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -676321.2500 - val_loss: -659368.4375\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -690884.3750 - val_loss: -673767.5625\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -706048.2500 - val_loss: -688252.0625\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -721251.0625 - val_loss: -703251.5000\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -736877.5000 - val_loss: -718387.0000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -752600.1875 - val_loss: -733771.1250\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -768684.3125 - val_loss: -749216.7500\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -784719.0625 - val_loss: -764906.8750\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -801257.0625 - val_loss: -780826.5000\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -817800.7500 - val_loss: -796916.4375\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -834654.4375 - val_loss: -813149.1875\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -851760.3125 - val_loss: -829905.2500\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -869316.0000 - val_loss: -846936.3125\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -886949.9375 - val_loss: -864135.4375\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -904923.8125 - val_loss: -881479.8750\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -922896.9375 - val_loss: -898991.5625\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -941240.1250 - val_loss: -916634.0000\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -959656.3750 - val_loss: -934675.0000\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -978420.5625 - val_loss: -952734.9375\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 5ms/step - loss: -997385.8750 - val_loss: -971026.3750\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: -1016374.2500 - val_loss: -989696.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16f8f6090>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train for 50 epochs\n",
    "\n",
    "# Have to change the type or else it won't be able to convert to tensor.\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95fe399f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 883us/step\n",
      "[[ 655.86084    0.       557.7253  ...  864.8463   734.0905   771.742  ]\n",
      " [ 801.07404    0.       677.8917  ... 1058.7328   896.90125  943.4249 ]\n",
      " [1822.5875     0.      1528.4849  ... 2416.461   2046.4308  2147.1663 ]\n",
      " ...\n",
      " [2128.4148     0.      1783.9331  ... 2822.5056  2389.8518  2507.1907 ]\n",
      " [1094.4106     0.       931.779   ... 1445.2452  1223.7429  1290.644  ]\n",
      " [ 660.27545    0.       570.44507 ...  867.58685  736.1916   778.64777]]\n",
      "(589, 20)\n"
     ]
    }
   ],
   "source": [
    "encoded = encoder.predict(x_test)\n",
    "print(encoded)\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4639ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded = decoder.predict(encoded)\n",
    "# print(decoded)\n",
    "# print(decoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.cluster import KMeans\n",
    "# import pandas as pd\n",
    "\n",
    "# num_clusters = 25\n",
    "\n",
    "# kmeans = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "# sc = MinMaxScaler(feature_range=(0, 1))\n",
    "# X = sc.fit_transform(encoded)\n",
    "\n",
    "# kmeans.fit(X)\n",
    "# # kmeans.fit(data[0])\n",
    "# cluster_assignments = kmeans.labels_\n",
    "# print(cluster_assignments)\n",
    "# print(len(cluster_assignments))\n",
    "\n",
    "# # Create a dictionary to store data points for each cluster\n",
    "# clustered_data = {cluster_num: [] for cluster_num in range(num_clusters)}\n",
    "\n",
    "# # Assign data points to their respective clusters\n",
    "# for i in range(len(X)):\n",
    "#     cluster_num = cluster_assignments[i]\n",
    "#     row = bomDf[bomDf['ID'] == i]\n",
    "#     clustered_data[cluster_num].append(row['Spool'].values)\n",
    "\n",
    "# # print(\"Lengths of arrays:\")\n",
    "\n",
    "# # for key, value in clustered_data.items():\n",
    "# #     print(f\"{key}: {len(value)}\")\n",
    "\n",
    "# max_length = max(len(value) for value in clustered_data.values())\n",
    "\n",
    "# # Fill in with None for arrays with shorter length\n",
    "# clustered_data_filled = {\n",
    "#     key: value + [None] * (max_length - len(value)) for key, value in clustered_data.items()}\n",
    "\n",
    "# # print(\"Lengths of arrays:\")\n",
    "\n",
    "# # for key, value in clustered_data_filled.items():\n",
    "# #     print(f\"{key}: {len(value)}\")\n",
    "\n",
    "# df = pd.DataFrame(clustered_data_filled)\n",
    "\n",
    "# df\n",
    "# # Save the DataFrame to a CSV file\n",
    "# # df.to_csv('Example3SpoolClusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43bc25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
