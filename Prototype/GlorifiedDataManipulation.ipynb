{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b0f92",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Need to install this version as it is deprecated in the kernel\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m spacy download en_core_web_sm\n",
    "!{sys.executable} -m pip install openai\n",
    "# !{sys.executable} -m pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf33a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Import the datasets\n",
    "\n",
    "# schedDf = pd.read_csv('CE Input/Prototype Schedule Input.csv')\n",
    "# bomDf = pd.read_csv('CE Input/Prototype Materials Input (Updated).csv')\n",
    "# csv_out_path = \"CE Output/Output-CEModelProcess (GlorifiedDataManipulation).csv\"\n",
    "\n",
    "schedDf = pd.read_csv('CE Input/Prototype 2 Schedule Input (Updated).csv')\n",
    "bomDf = pd.read_csv('CE Input/Prototype 2 Materials Input (Updated).csv')\n",
    "csv_out_path = \"CE Output/Output-CEModelProcess Prototype 2(GlorifiedDataManipulation).csv\"\n",
    "\n",
    "# Import the word model\n",
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b3ac8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from torch import cosine_similarity\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def word2vec(model, word):\n",
    "    return model[word.lower()]\n",
    "\n",
    "def sentence2vec(value, model):\n",
    "    sentence = value.split()\n",
    "\n",
    "    # Initialize an empty vector to store the sentence vector\n",
    "    sentence_vector = np.zeros(model.vector_size)\n",
    "\n",
    "    # Counter to keep track of the number of words in the sentence\n",
    "    word_count = 0\n",
    "\n",
    "    # Calculate the sum of word vectors for the words in the sentence\n",
    "    for word in sentence:\n",
    "        if word.lower() in model:\n",
    "            sentence_vector += model[word.lower()]\n",
    "            word_count += 1\n",
    "\n",
    "    # Check if there are words in the sentence that have embeddings\n",
    "    if word_count > 0:\n",
    "        # Calculate the average by dividing by the number of words\n",
    "        sentence_vector /= word_count\n",
    "    return sentence_vector\n",
    "\n",
    "def cosineSimilarity(vector1, vector2):\n",
    "\n",
    "    word_vector = torch.tensor(vector1).clone().detach().requires_grad_(True)\n",
    "    sentence_vector = torch.tensor(vector2).clone().detach().requires_grad_(True)\n",
    "    # Calculate cosine similarity between the sentence embeddings\n",
    "    similarity = cosine_similarity(\n",
    "        word_vector.unsqueeze(0), sentence_vector.unsqueeze(0))\n",
    "    val = similarity[0].item()\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95caea7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Feature Modelling\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "\n",
    "date_format = \"%m/%d/%Y\"\n",
    "\n",
    "bomDf.dropna(subset=['Material BOM'], inplace=True)\n",
    "schedDf.dropna(subset=['Activity Description'], inplace=True)\n",
    "\n",
    "# Remove all whitespace\n",
    "bomDf = bomDf.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "schedDf = schedDf.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# startDate = datetime.strptime(row[2].strip(), date_format)\n",
    "# endDate = datetime.strptime(row[3].strip(), date_format)\n",
    "# ProcStepDuration = str(endDate-startDate).split(',')[0]\n",
    "\n",
    "\n",
    "# Create SemanticWordVec Feature\n",
    "schedDf['SemanticWordVec'] = schedDf['Activity Description'].apply(sentence2vec, args = (model,))\n",
    "\n",
    "# Create Duration Feature\n",
    "schedDf['Duration'] = schedDf.apply(lambda row: str(datetime.strptime(row['End Date'], date_format) - datetime.strptime(row['Start Date'], date_format)).split(',')[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e83d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# PROCSTEP\n",
    "\n",
    "threshold = 0.95\n",
    "\n",
    "# Array of 2D data [activity description, wordvec]\n",
    "selected_columns = schedDf[['Activity Description', 'SemanticWordVec']].values.tolist()\n",
    "# print(selected_columns[0])\n",
    "\n",
    "for i, row1 in enumerate(selected_columns):\n",
    "    for j, row2 in enumerate(selected_columns[i+1:]):\n",
    "        cosine_sim = cosineSimilarity(row1[1], row2[1])\n",
    "        if cosine_sim > threshold:\n",
    "            print(row1[0], row2[0], cosine_sim)\n",
    "            row1.append(1)\n",
    "            selected_columns.remove(row2)\n",
    "            \n",
    "for i in selected_columns:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640a90d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# PROCESSOUTPUT\n",
    "# Try to use ML model?\n",
    "\n",
    "import openai\n",
    "import os\n",
    "import ast\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "activity_list = [i[0] for i in selected_columns]\n",
    "\n",
    "def findProcessOutputOpenAi():\n",
    "    prompt = \"You will be given a list of sub tasks. Answer this question for each sub task: _ is a sub task you need to fulfil in order to complete which part of a building? Example: 'Install Tiles'. Output: 'Roof'. Answer in one word only, and make sure the keys are identical to the values in the input list. Return a python dictionary. Here is the list of sub tasks: \" + \\\n",
    "        ', '.join(map(str, activity_list))\n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        best_of=1\n",
    "    )\n",
    "    # Convert ChatGPT Output to Dictionary.\n",
    "    my_dict = ast.literal_eval(response['choices'][0]['text'].strip())\n",
    "    return my_dict\n",
    "\n",
    "# print(findProcessOutputOpenAi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f406cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# PROCESS SUCCESSOR\n",
    "# Try to use ML model?\n",
    "\n",
    "def findProcessStepSuccessorOpenAi():\n",
    "    prompt = \"You will be given a list of sub tasks. These sub tasks are done sequentially, and your job is to determine which task precedes/succeeds the other. Answer in one word only, and make sure the keys are identical to the input list. Return a python dictionary. Here is the list of sub tasks: \" + \\\n",
    "        ', '.join(map(str, activity_list))\n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        best_of=1\n",
    "    )\n",
    "#     return response\n",
    "    my_dict = ast.literal_eval(response['choices'][0]['text'].strip())\n",
    "    return my_dict\n",
    "\n",
    "# print(findProcessStepSuccessorOpenAi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30aa61",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# MATERIAL ASSIGNMENT\n",
    "\n",
    "import copy\n",
    "\n",
    "# Thinking: compare cosine_sim of each row to categories in scheduleDF. Assign each material to the category that is most similar.\n",
    "categories_wordVec = [[inner_list[0], inner_list[1]] for inner_list in selected_columns]\n",
    "categories_only = [inner_list[0] for inner_list in selected_columns]\n",
    "\n",
    "# Key: activity, Value: Empty list\n",
    "my_dict = {key: [] for key in categories_only}\n",
    "\n",
    "materialAssignment = copy.deepcopy(my_dict)\n",
    "\n",
    "material_list = bomDf['Material BOM'].values.tolist()\n",
    "\n",
    "# FIRST = \"You will be given a list of materials and a list of activities. Your job is to determine which material is required to perform which activity. Some activities don't require any materials and some activities require multiple materials. If you are unsure, assign a material to the activity with the highest probability. Return a python dictionary, and make sure the keys are identical to the input list. Here is the list of activities: \" + \\\n",
    "#         ', '.join(map(str, activity_list)) + \". \" + \"Here is the list of materials: \" + \\\n",
    "#         ', '.join(map(str, material_list))\n",
    "\n",
    "\n",
    "# def findMaterialAssignmentOpenAi():\n",
    "#     prompt = \"Assign the following list of materials to the most likely activity it is associated with. Some activities don't require any materials and some activities require multiple materials. Return a python dictionary, and make sure the keys are identical to the input list. Here is the list of activities: \" + \\\n",
    "#         ', '.join(map(str, activity_list)) + \". \" + \"Here is the list of materials: \" + \\\n",
    "#         ', '.join(map(str, material_list))\n",
    "#     response = openai.Completion.create(\n",
    "#         model=\"gpt-3.5-turbo-instruct\",\n",
    "#         prompt=prompt,\n",
    "#         max_tokens=2000,\n",
    "#         temperature=0,\n",
    "#         best_of=1\n",
    "#     )\n",
    "#     my_dict = ast.literal_eval(response['choices'][0]['text'].strip())\n",
    "#     return my_dict\n",
    "\n",
    "for index, row in bomDf.iterrows():\n",
    "    highest = -1\n",
    "    assignment = None\n",
    "    activity_desc = row[0]\n",
    "    wordVec1 = sentence2vec(row[0], model)\n",
    "    for category in categories_wordVec:\n",
    "        wordVec2 = category[1]\n",
    "        cosine_sim = cosineSimilarity(wordVec1, wordVec2)\n",
    "        if cosine_sim > highest:\n",
    "            highest = cosine_sim\n",
    "            assignment = category[0]\n",
    "    materialAssignment[assignment].append(row[1])\n",
    "\n",
    "# print(materialAssignment)\n",
    "# materialAssignment Stores the Assignments from BOM to Schedule..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983fe10",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# BatchSize\n",
    "\n",
    "non_empty_activities = {key: value for key, value in materialAssignment.items() if len(value) > 0}\n",
    "\n",
    "batchSize = copy.deepcopy(my_dict)\n",
    "\n",
    "# for i in non_empty_activities.values():\n",
    "#     print(i)\n",
    "\n",
    "# for i in non_empty_keys.keys():\n",
    "#     print(i)\n",
    "# print(non_empty_keys)\n",
    "\n",
    "num_duplicates = {sublist[0]: len(sublist)-1 for sublist in selected_columns}\n",
    "\n",
    "for key, value in non_empty_activities.items():\n",
    "    for material in value:\n",
    "        amount = int(bomDf.loc[bomDf['Material BOM'] == material]['Amount'].values)\n",
    "        batchSize[key].append(amount/num_duplicates[key])\n",
    "\n",
    "# print(batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e3634",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Duration\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_format = \"%m/%d/%Y\"\n",
    "\n",
    "duration = copy.deepcopy(my_dict)\n",
    "\n",
    "for key in duration.keys():\n",
    "    start = datetime.strptime(schedDf[schedDf['Activity Description'] == key]['Start Date'].values.tolist()[0], date_format)\n",
    "    end = datetime.strptime(schedDf[schedDf['Activity Description'] == key]['End Date'].values.tolist()[0], date_format)\n",
    "    duration[key] = str(end-start).split(',')[0]\n",
    "\n",
    "# print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357eed43",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Resource Assignment\n",
    "\n",
    "resourceAssignment = copy.deepcopy(my_dict)\n",
    "\n",
    "for key in duration.keys():\n",
    "    resource = schedDf[schedDf['Activity Description'] == key]['Subcontractor'].values.tolist()[0]\n",
    "    resourceAssignment[key] = resource\n",
    "    \n",
    "# print(resourceAssignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d4f83a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Resource Quantity\n",
    "\n",
    "resourceQuantity = {}\n",
    "\n",
    "\n",
    "for subcontractor in schedDf['Subcontractor'].unique():\n",
    "    filteredDf = schedDf[schedDf['Subcontractor'] == subcontractor]\n",
    "    max_value = filteredDf['Manpower'].max()\n",
    "    resourceQuantity[subcontractor] = max_value\n",
    "    \n",
    "# print(resourceQuantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1301f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Output Configuration!!\n",
    "\n",
    "import csv\n",
    "\n",
    "output_data = [[\"ID\", \"ProcessOutput\", \"ProcStep\", \"ProcStepSuccessor\", \"ProcStepDuration\",\n",
    "                    \"ProcMaterialAssignment\", \"ProcMaterialBatchSize\", \"ProcResourceAssignment\", \"ProcResourceQuantity\"]]\n",
    "\n",
    "processOutput = findProcessOutputOpenAi()\n",
    "processSuccessor = findProcessStepSuccessorOpenAi()\n",
    "\n",
    "def findProcessOutput(activity):\n",
    "    return processOutput[activity.split(' - ')[0]]\n",
    "\n",
    "def findProcStepSuccessor(activity):\n",
    "    try:\n",
    "        out = processSuccessor[activity]\n",
    "        return out.split(' - ')[0]\n",
    "    except KeyError:\n",
    "        return []\n",
    "\n",
    "def findProcStepDuration(activity):\n",
    "    return duration[activity]\n",
    "\n",
    "def findProcMaterialAssignment(activity):\n",
    "    return materialAssignment[activity]\n",
    "\n",
    "def findProcMaterialBatchSize(activity):\n",
    "    return batchSize[activity]\n",
    "\n",
    "def findProcResourceAssignment(activity):\n",
    "    return resourceAssignment[activity]\n",
    "\n",
    "def findProcResourceQuantity(activity):\n",
    "    resAssignment = resourceAssignment[activity]\n",
    "    return resourceQuantity[resAssignment]\n",
    "\n",
    "data = [[i+1, findProcessOutput(item[0]), item[0].split(' - ')[0], findProcStepSuccessor(item[0]), findProcStepDuration(item[0]), findProcMaterialAssignment(item[0]), findProcMaterialBatchSize(item[0]), findProcResourceAssignment(item[0]), findProcResourceQuantity(item[0])] for i, item in enumerate(selected_columns)]\n",
    "\n",
    "for row in data:\n",
    "    output_data.append(row)\n",
    "\n",
    "with open(csv_out_path, 'w', newline='') as output_file:\n",
    "        csv_writer = csv.writer(output_file)\n",
    "\n",
    "        # Write the processed data to the output file\n",
    "        csv_writer.writerows(output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
